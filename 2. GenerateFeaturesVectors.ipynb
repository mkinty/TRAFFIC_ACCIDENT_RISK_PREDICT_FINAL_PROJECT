{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "509kXc7jA63t"
   },
   "source": [
    "### 1 -Importons les différentes librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xny8jifUzJXy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygeohash in /anaconda3/lib/python3.7/site-packages (1.2.0)\n",
      "Requirement already satisfied: haversine in /anaconda3/lib/python3.7/site-packages (2.1.2)\n",
      "ERROR: unknown command \"intall\" - maybe you meant \"install\"\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow-gpu==2.0.0beta1\n",
    "!pip install pygeohash \n",
    "!pip install haversine\n",
    "!pip intall pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "djpjrFWuA63x"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "import pytz\n",
    "import pygeohash as gh\n",
    "from haversine import haversine\n",
    "import time\n",
    "import pickle as cPickle\n",
    "import glob\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "geohash_prec = 5 # the geo-hash level to define a region R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YWcJ_rdWWMAQ"
   },
   "source": [
    "####*2 - Définnisons une classe weather qui utilise les données météorologiques pour créer des vecteurs features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sBM5b436A64t"
   },
   "outputs": [],
   "source": [
    "class weather:\n",
    "    date = ''\n",
    "    temp = 0.0\n",
    "    windchill = 0.0\n",
    "    humid = 0.0\n",
    "    pressure= 0.0\n",
    "    visib = 0.0\n",
    "    windspeed = 0.0\n",
    "    winddir = ''\n",
    "    precipitation = 0.0\n",
    "    events = ''\n",
    "    condition = ''\n",
    "    \n",
    "    def __init__(self, date, temp, windchill, humid, pressure, visib, windspeed, winddir, \n",
    "                 precipitation, events, condition, zone):\n",
    "        self.date = datetime.strptime(date, '%Y-%m-%d %I:%M:%S %p')\n",
    "        self.date = self.date.replace(tzinfo=pytz.timezone(zone))\n",
    "        self.temp = float(temp)\n",
    "        self.windchill = float(windchill)\n",
    "        self.humid = float(humid)\n",
    "        self.pressure = float(pressure)\n",
    "        self.visib = float(visib)\n",
    "        self.windspeed = float(windspeed)\n",
    "        self.winddir = winddir\n",
    "        self.precipitation = float(precipitation)\n",
    "        self.events = events\n",
    "        self.condition = condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nugDqz-1A64y"
   },
   "source": [
    "## *3 - Processus de création des vecteurs features de quelques villes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRvgRxZAA65p"
   },
   "source": [
    "### *3-1- Choix des villes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJTfdiz1A65q"
   },
   "outputs": [],
   "source": [
    "cities = {'LosAngeles': [33.700615, 34.353627, -118.683511, -118.074559], \n",
    "           'Houston': [29.497907,30.129003,-95.797178,-94.988191],\n",
    "           'Austin': [30.079327, 30.596764,-97.968881,-97.504838],\n",
    "           'Dallas': [32.559567,33.083278,-97.036586,-96.428928],\n",
    "           'Charlotte': [34.970168,35.423667,-81.060925,-80.622687],\n",
    "           'Atlanta': [33.612410,33.916999,-84.575600,-84.231911]}\n",
    "\n",
    "time_zones = {'Houston':'US/Central', 'Charlotte':'US/Eastern', 'Dallas':'US/Central',\n",
    "              'Atlanta':'US/Eastern', 'Austin':'US/Central', 'LosAngeles':'US/Pacific'}\n",
    "\n",
    "# time interval to sample data for \n",
    "start = datetime(2018, 6, 1)\n",
    "finish   = datetime(2018, 9, 2)\n",
    "\n",
    "begin = datetime.strptime('2018-06-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "end   = datetime.strptime('2018-08-31 23:59:59', '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4NbKH_IA656"
   },
   "source": [
    "### *3-2- Définissons UTC comme fuseau horaire par défaut pour chaque événement de trafic*\n",
    "\n",
    "##### *On crée un dictionnaire df_city2incidents qui contient les clés suivantes :* \n",
    "*a - EventId*\n",
    "\n",
    "*b - Type*\n",
    "\n",
    "*c - LocationLat*\n",
    "\n",
    "*d - LocationLng*\n",
    "\n",
    "*e - StartTime(UTC)*\n",
    "\n",
    "*f - EndTime(UTC)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12069,
     "status": "ok",
     "timestamp": 1574091910730,
     "user": {
      "displayName": "Moustapha KINTY",
      "photoUrl": "",
      "userId": "03984028447163486280"
     },
     "user_tz": -60
    },
    "id": "saWcLxQdA65_",
    "outputId": "ee213db5-d2e6-483d-8447-2caca7078c9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TW_EVENT LosAngeles 90961\n",
      "TW_EVENT Houston 45463\n",
      "TW_EVENT Austin 20438\n",
      "TW_EVENT Dallas 30543\n",
      "TW_EVENT Charlotte 18592\n",
      "TW_EVENT Atlanta 23943\n"
     ]
    }
   ],
   "source": [
    "## converting time from UTC to local time zone for each city \n",
    "path = 'data/temporary/' #create this temporary directory inside the '/data' folder\n",
    "df_city2incidents = {}\n",
    "for c in cities:\n",
    "    incidents = []\n",
    "    z = time_zones[c]\n",
    "    \n",
    "    with open(path + 'TW_EVENT_{}_20180601_20180609.csv'.format(c), 'r') as file:\n",
    "        header = False\n",
    "        for line in file:\n",
    "            if not header:\n",
    "                header = True\n",
    "                continue\n",
    "            parts = line.replace('\\r', '').replace('\\n', '').split(',')\n",
    "            \n",
    "            ds = datetime.strptime(parts[6].replace('T',' '), '%Y-%m-%d %H:%M:%S')\n",
    "            ds = ds.replace(tzinfo=pytz.utc)\n",
    "            ds = ds.astimezone(pytz.timezone(z))\n",
    "            \n",
    "            de = datetime.strptime(parts[7].replace('T',' '), '%Y-%m-%d %H:%M:%S')\n",
    "            de = de.replace(tzinfo=pytz.utc)\n",
    "            de = de.astimezone(pytz.timezone(z))\n",
    "            \n",
    "            v = [parts[0], parts[2], float(parts[9]), float(parts[10]), ds, de]            \n",
    "            incidents.append(v)\n",
    "            \n",
    "    df_city2incidents[c] = incidents\n",
    "    print('TW_EVENT', c, len(incidents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2JxaHGBKA66L"
   },
   "source": [
    "### *3-3- Construisons des vecteurs de fonction paires City-Geohash*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9p17-EEmA66M"
   },
   "outputs": [],
   "source": [
    "zone_to_be = {}\n",
    "\n",
    "for z in ['US/Eastern', 'US/Central', 'US/Mountain', 'US/Pacific']:\n",
    "    t_begin = begin.replace(tzinfo=pytz.timezone(z))\n",
    "    t_end   = end.replace(tzinfo=pytz.timezone(z))\n",
    "    zone_to_be[z] = [t_begin, t_end]\n",
    "\n",
    "name_conversion = {'Broken-Vehicle':'BrokenVehicle', 'Flow-Incident': 'FlowIncident', 'Lane-Blocked':'RoadBlocked'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TPcAGAdjA66i"
   },
   "source": [
    "#### *3-4- Créons des dictionnaires city_to_geohashes, geocode_to_airport et aiport_to_timezone qui contiennent respectivement les dictionaires des villes, le code des aeroports et  le code des aeroports et les timeZone*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wr_ebX1FQeXH"
   },
   "outputs": [],
   "source": [
    "def return_interval_index(time_stamp, start, end):\n",
    "    if time_stamp < start or time_stamp>end: \n",
    "        return -1\n",
    "    index = int(((time_stamp - start).days*24*60 + (time_stamp-start).seconds/60)/15)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25573,
     "status": "ok",
     "timestamp": 1574094925809,
     "user": {
      "displayName": "Moustapha KINTY",
      "photoUrl": "",
      "userId": "03984028447163486280"
     },
     "user_tz": -60
    },
    "id": "saW3all-A66j",
    "outputId": "883b89f6-7010-420e-b7a1-b109d2faac60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LosAngeles in 9.6 sec! there are 156 geohashes with data!\n",
      "Done with Houston in 6.1 sec! there are 249 geohashes with data!\n",
      "Done with Austin in 3.7 sec! there are 130 geohashes with data!\n",
      "Done with Dallas in 6.0 sec! there are 164 geohashes with data!\n",
      "Done with Charlotte in 3.4 sec! there are 114 geohashes with data!\n",
      "Done with Atlanta in 4.1 sec! there are 68 geohashes with data!\n"
     ]
    }
   ],
   "source": [
    "diff = int(((end - begin).days*24*60 + (end-begin).seconds/60)/15) # total_minutes/15 ==> number of 15 minutes intervals\n",
    "\n",
    "path = 'data/temporary/'\n",
    "city_to_geohashes = {}\n",
    "for c in cities: city_to_geohashes[c] = {}\n",
    "\n",
    "start_timestamp = time.time()\n",
    "ccnntt = 0\n",
    "\n",
    "geocode_to_airport = {}\n",
    "aiport_to_timezone = {}\n",
    "\n",
    "for c in cities:\n",
    "    z = time_zones[c]\n",
    "    \n",
    "    # add map-quest data\n",
    "    with open(path + 'TW_EVENT_{}_20180601_20180609.csv'.format(c), 'r') as file:\n",
    "        header = False\n",
    "        for line in file:\n",
    "            if not header:\n",
    "                header = True\n",
    "                continue\n",
    "            parts = line.replace('\\r', '').replace('\\n', '').split(',')\n",
    "            \n",
    "            ds = datetime.strptime(parts[6].replace('T',' '), '%Y-%m-%d %H:%M:%S')\n",
    "            ds = ds.replace(tzinfo=pytz.utc)\n",
    "            ds = ds.astimezone(pytz.timezone(z))\n",
    "            s_interval = return_interval_index(ds, zone_to_be[z][0], zone_to_be[z][1])\n",
    "            if s_interval==-1: continue\n",
    "                \n",
    "            de = datetime.strptime(parts[7].replace('T',' '), '%Y-%m-%d %H:%M:%S')\n",
    "            de = de.replace(tzinfo=pytz.utc)\n",
    "            de = de.astimezone(pytz.timezone(z))\n",
    "            e_interval = return_interval_index(de, zone_to_be[z][0], zone_to_be[z][1])\n",
    "            if e_interval == -1: \n",
    "              e_interval = diff-1    \n",
    "            \n",
    "            start_gh = gh.encode(float(parts[9]), float(parts[10]), precision=geohash_prec)\n",
    "            intervals = []\n",
    "            if start_gh not in city_to_geohashes[c]:\n",
    "                for i in range(diff): \n",
    "                    intervals.append({'Construction':0, 'Congestion':0, 'Accident':0, 'FlowIncident':0, 'Event':0, \n",
    "                                      'BrokenVehicle':0, 'RoadBlocked':0, 'Other':0})\n",
    "            else:\n",
    "                intervals = city_to_geohashes[c][start_gh]\n",
    "            \n",
    "            if parts[2] in name_conversion:\n",
    "                tp = name_conversion[parts[2]]\n",
    "            else: \n",
    "                tp = parts[2].split('-')[0]\n",
    "                \n",
    "            for i in range(s_interval, e_interval+1):                \n",
    "                v = intervals[i]\n",
    "                if tp in v: \n",
    "                  v[tp] = v[tp] + 1\n",
    "                else: \n",
    "                  v['Other'] = v['Other'] + 1\n",
    "                intervals[i] = v\n",
    "                \n",
    "                if tp == 'Accident': break # unlike other types of traffic events, \n",
    "                \n",
    "            city_to_geohashes[c][start_gh] = intervals\n",
    "            \n",
    "            ap = parts[12]\n",
    "            if len(ap) > 3:\n",
    "                if start_gh not in geocode_to_airport:\n",
    "                    geocode_to_airport[start_gh] = set([ap])\n",
    "                else:\n",
    "                    st = geocode_to_airport[start_gh]\n",
    "                    st.add(ap)\n",
    "                    geocode_to_airport[start_gh] = st\n",
    "                aiport_to_timezone[ap] = z\n",
    "  \n",
    "    \n",
    "    print('Done with {} in {:.1f} sec! there are {} geohashes with data!'.format(c, \n",
    "                                time.time()-start_timestamp, len(city_to_geohashes[c])))\n",
    "    start_timestamp = time.time()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3yjKKMCDBWNS"
   },
   "source": [
    "###### 3-5- Utilisons les Datasets de Sample_Weather, pour créer un dictionnaire de données des codes des aeroports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Dy7twWmXqZc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airport</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temp</th>\n",
       "      <th>WindChill</th>\n",
       "      <th>Humd</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Visib</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDir</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Events</th>\n",
       "      <th>Conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35642</th>\n",
       "      <td>KATL</td>\n",
       "      <td>2019-6-30</td>\n",
       "      <td>7:52 PM</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>28.92</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>WSW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35643</th>\n",
       "      <td>KATL</td>\n",
       "      <td>2019-6-30</td>\n",
       "      <td>8:52 PM</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>28.91</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>WSW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35644</th>\n",
       "      <td>KATL</td>\n",
       "      <td>2019-6-30</td>\n",
       "      <td>9:52 PM</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>28.92</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>W</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35645</th>\n",
       "      <td>KATL</td>\n",
       "      <td>2019-6-30</td>\n",
       "      <td>10:52 PM</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>28.95</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>W</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35646</th>\n",
       "      <td>KATL</td>\n",
       "      <td>2019-6-30</td>\n",
       "      <td>11:52 PM</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>28.97</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>W</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Airport       Date      Hour  Temp  WindChill  Humd  Pressure  Visib  \\\n",
       "35642    KATL  2019-6-30   7:52 PM  86.0       86.0  55.0     28.92   10.0   \n",
       "35643    KATL  2019-6-30   8:52 PM  83.0       83.0  63.0     28.91   10.0   \n",
       "35644    KATL  2019-6-30   9:52 PM  81.0       81.0  67.0     28.92   10.0   \n",
       "35645    KATL  2019-6-30  10:52 PM  79.0       79.0  69.0     28.95   10.0   \n",
       "35646    KATL  2019-6-30  11:52 PM  77.0       77.0  76.0     28.97   10.0   \n",
       "\n",
       "       WindSpeed WindDir  Precipitation Events     Conditions  \n",
       "35642        9.0     WSW            0.0    NaN  Mostly Cloudy  \n",
       "35643        8.0     WSW            0.0    NaN  Mostly Cloudy  \n",
       "35644       10.0       W            0.0    NaN  Partly Cloudy  \n",
       "35645        8.0       W            0.0    NaN  Partly Cloudy  \n",
       "35646        7.0       W            0.0    NaN           Fair  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/Sample_Weather/KATL.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 67289,
     "status": "ok",
     "timestamp": 1574095570293,
     "user": {
      "displayName": "Moustapha KINTY",
      "photoUrl": "",
      "userId": "03984028447163486280"
     },
     "user_tz": -60
    },
    "id": "NuxApVHw848m",
    "outputId": "7a1794c1-454f-499e-b48d-e8bc98a67c29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 airports to collect data for!\n",
      "Airport KSLI\n",
      "Airport KLGB\n",
      "Airport KLAX\n",
      "Airport KHHR\n",
      "Airport KSMO\n",
      "Airport KVNY\n",
      "Airport KBUR\n",
      "Airport KTOA\n",
      "Airport KCQT\n",
      "Airport KFUL\n",
      "Airport KWHP\n",
      "Airport KEMT\n",
      "Airport K3A6\n",
      "Airport KGXA\n",
      "Airport KPMD\n",
      "Airport KMCJ\n",
      "Airport KHOU\n",
      "Airport KSGR\n",
      "Airport KDWH\n",
      "Airport KTME\n",
      "Airport KIAH\n",
      "Airport KEFD\n",
      "Airport KAXH\n",
      "Airport KLVJ\n",
      "Airport K6R3\n",
      "Airport KAUS\n",
      "Airport KATT\n",
      "Airport KRYW\n",
      "Airport KEDC\n",
      "Airport KGTU\n",
      "Airport KRBD\n",
      "Airport KDAL\n",
      "Airport KADS\n",
      "Airport KDFW\n",
      "Airport KGPM\n",
      "Airport KLNC\n",
      "Airport KF46\n",
      "Airport KHQZ\n",
      "Airport KTKI\n",
      "Airport KDTO\n",
      "Airport KGKY\n",
      "Airport KCLT\n",
      "Airport KJQF\n",
      "Airport KEQY\n",
      "Airport KUZA\n",
      "Airport KAKH\n",
      "Airport KIPJ\n",
      "Airport KATL\n",
      "Airport KFTY\n",
      "Airport KPDK\n",
      "Airport KMGE\n",
      "\n",
      "Data for 51 airport stations is loaded!\n"
     ]
    }
   ],
   "source": [
    "# load and sort relevant weather data\n",
    "airports_to_observations = {}\n",
    "for g in geocode_to_airport:\n",
    "    aps = geocode_to_airport[g]\n",
    "    for a in aps:\n",
    "        if a not in airports_to_observations:\n",
    "            airports_to_observations[a] = []\n",
    "\n",
    "print('{} airports to collect data for!'.format(len(airports_to_observations)))\n",
    "            \n",
    "w_path = 'data/Sample_Weather/' # this directory contains weather observation records for each airport\n",
    "# a sample data file can be find in '/data' directory (Sample_Weather.tar.gz)\n",
    "airport_to_data = {}\n",
    "for ap in airports_to_observations:\n",
    "    data = []\n",
    "    z = aiport_to_timezone[ap]\n",
    "    print('Airport {}'.format(ap))\n",
    "    header = ''\n",
    "    with open(w_path + ap + '.csv', 'r') as file:\n",
    "        for line in file:\n",
    "            if 'Airport' in line: \n",
    "                header = line.replace('\\r','').replace('\\n','').replace(',Hour','')\n",
    "                continue\n",
    "            parts = line.replace('\\r', '').replace('\\n', '').split(',')\n",
    "            try:\n",
    "                w = weather(parts[1] + ' ' + parts[2].split(' ')[0] + ':00 ' + parts[2].split(' ')[1], parts[3], parts[4], \n",
    "                           parts[5], parts[6], parts[7], parts[8], parts[9], parts[10], parts[11], parts[12], z)   \n",
    "                data.append(w)\n",
    "            except:\n",
    "                continue\n",
    "    data.sort(key=lambda x:x.date)\n",
    "    airport_to_data[ap] = data\n",
    "    \n",
    "print('\\nData for {} airport stations is loaded!'.format(len(airport_to_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TRN3zkLVZQXu"
   },
   "source": [
    "##### *3-6- Trouvons les aéroports manquants*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4ZeP_zGB96D"
   },
   "outputs": [],
   "source": [
    "for c in city_to_geohashes:\n",
    "    for g in city_to_geohashes[c]:\n",
    "        if g not in geocode_to_airport:\n",
    "            gc = gh.decode_exactly(g)[0:2]\n",
    "            min_dist = 1000000000\n",
    "            close_g = ''\n",
    "            for _g in geocode_to_airport:\n",
    "                _gc = gh.decode_exactly(_g)[0:2]\n",
    "                dst = haversine(gc, _gc, 'km')\n",
    "                if dst < min_dist:\n",
    "                    min_dist = dst\n",
    "                    close_g = _g\n",
    "#            print(g, close_g, min_dist)\n",
    "            geocode_to_airport[g] = geocode_to_airport[close_g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 129218,
     "status": "ok",
     "timestamp": 1574095964168,
     "user": {
      "displayName": "Moustapha KINTY",
      "photoUrl": "",
      "userId": "03984028447163486280"
     },
     "user_tz": -60
    },
    "id": "o5sb5oZfaVAS",
    "outputId": "d034c22b-f5b6-4cd0-ddc9-7a6ab162885e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LosAngeles in 26.7 sec!\n",
      "Done with Houston in 50.1 sec!\n",
      "Done with Austin in 45.3 sec!\n",
      "Done with Dallas in 88.7 sec!\n",
      "Done with Charlotte in 95.0 sec!\n",
      "Done with Atlanta in 8.8 sec!\n"
     ]
    }
   ],
   "source": [
    "city_to_geohashes_to_weather = {}\n",
    "\n",
    "for c in city_to_geohashes:\n",
    "    start = time.time()\n",
    "    geo2weather = {}\n",
    "    for g in city_to_geohashes[c]:\n",
    "        w_data = []\n",
    "        for i in range(len(city_to_geohashes[c][g])):\n",
    "            w_data.append({'Temperature':[], 'Humidity':[], 'Pressure':[], 'Visibility':[], 'WindSpeed':[], \n",
    "                          'Precipitation':[], 'Condition':set(), 'Event':set()})\n",
    "        # populate weather data\n",
    "        aps = geocode_to_airport[g]\n",
    "        for a in aps:\n",
    "            z = aiport_to_timezone[a]\n",
    "            a_w_data = airport_to_data[a]\n",
    "            prev = 0\n",
    "            for a_w_d in a_w_data:\n",
    "                idx = return_interval_index(a_w_d.date, zone_to_be[z][0], zone_to_be[z][1])\n",
    "                if idx >-1:\n",
    "                    for i in range(prev, min(idx+1, len(w_data))):\n",
    "                        _w = w_data[i]\n",
    "                        \n",
    "                        _tmp = _w['Temperature']\n",
    "                        if a_w_d.temp > -1000:\n",
    "                            _tmp.append(a_w_d.temp)\n",
    "                            _w['Temperature'] = _tmp\n",
    "                        \n",
    "                        _hmd = _w['Humidity']\n",
    "                        if a_w_d.humid > -1000:\n",
    "                            _hmd.append(a_w_d.humid)\n",
    "                            _w['Humidity'] = _hmd\n",
    "                        \n",
    "                        _prs = _w['Pressure']\n",
    "                        if a_w_d.pressure > -1000:\n",
    "                            _prs.append(a_w_d.pressure)\n",
    "                            _w['Pressure'] = _prs\n",
    "                        \n",
    "                        _vis = _w['Visibility']\n",
    "                        if a_w_d.visib > -1000:\n",
    "                            _vis.append(a_w_d.visib)\n",
    "                            _w['Visibility'] = _vis\n",
    "                            \n",
    "                        _wspd = _w['WindSpeed']\n",
    "                        if a_w_d.windspeed > -1000:\n",
    "                            _wspd.append(a_w_d.windspeed)\n",
    "                            _w['WindSpeed'] = _wspd\n",
    "                            \n",
    "                        _precip = _w['Precipitation']\n",
    "                        if a_w_d.precipitation > -1000:\n",
    "                            _precip.append(a_w_d.precipitation)\n",
    "                            _w['Precipitation'] = _precip\n",
    "                            \n",
    "                        _cond = _w['Condition']\n",
    "                        _cond.add(a_w_d.condition)\n",
    "                        _w['Condition'] = _cond\n",
    "                        \n",
    "                        _evnt = _w['Event']\n",
    "                        _evnt.add(a_w_d.events)\n",
    "                        _w['Event'] = _evnt\n",
    "                        \n",
    "                        w_data[i] = _w\n",
    "                        \n",
    "                    prev = idx+1\n",
    "                                                \n",
    "            \n",
    "        geo2weather[g] = w_data\n",
    "    city_to_geohashes_to_weather[c] = geo2weather\n",
    "    print('Done with {} in {:.1f} sec!'.format(c, time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Scattered Clouds', 'Fair'}\n"
     ]
    }
   ],
   "source": [
    "print(_w['Condition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "onqgaZFQ2OFy"
   },
   "source": [
    "#### *3-7- Ajouter le Dataset Daylight*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpdWjVVabjmW"
   },
   "outputs": [],
   "source": [
    "class dayLight:\n",
    "    sunrise = []\n",
    "    sunset = []\n",
    "    def __init__(self, sunrise, sunset):\n",
    "        self.sunrise = sunrise\n",
    "        self.sunset = sunset\n",
    "        \n",
    "def return_time(x):\n",
    "    try:\n",
    "        h = int(x.split(':')[0])\n",
    "        m = int(x.split(':')[1].split(' ')[0])\n",
    "        if 'pm' in x and h < 12: h = h + 12\n",
    "        return [h,m]\n",
    "    except: return [0,0]\n",
    "\n",
    "    \n",
    "def returnDayLight(city, state, dt):\n",
    "    sc = city + '-' + state\n",
    "    days = city_days_time[sc]\n",
    "    d = str(dt.year) + '-' + str(dt.month) + '-' + str(dt.day)\n",
    "    if d in days:\n",
    "        r = days[d]\n",
    "        if ((dt.hour>r.sunrise[0] and dt.hour<r.sunset[0]) or\n",
    "            (dt.hour>=r.sunrise[0] and dt.minute>=r.sunrise[1] and dt.hour<r.sunset[0]) or\n",
    "            (dt.hour>r.sunrise[0] and dt.hour<=r.sunset[0] and dt.minute<r.sunset[1]) or \n",
    "            (dt.hour>=r.sunrise[0] and dt.minute>=r.sunrise[1] and dt.hour<=r.sunset[0] and dt.minute<r.sunset[1])):\n",
    "            return '1'\n",
    "        else: return '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1574097345985,
     "user": {
      "displayName": "Moustapha KINTY",
      "photoUrl": "",
      "userId": "03984028447163486280"
     },
     "user_tz": -60
    },
    "id": "x7qLLpnExhTj",
    "outputId": "bd22d348-b053-4690-96e0-23f5f034cf2b"
   },
   "outputs": [],
   "source": [
    "city_days_time = {}\n",
    "\n",
    "days = {}\n",
    "city = ''\n",
    "with open('data/sample_daylight.csv', 'r') as file: # you find daylight data for the selected 6 cities in this file\n",
    "    for ln in file.readlines():\n",
    "        parts = ln.replace('\\r','').replace('\\n','').split(',')\n",
    "\n",
    "        if parts[0] != city:\n",
    "            if len(city) > 0: \n",
    "                if city in city_days_time:\n",
    "                    _days = city_days_time[city]\n",
    "                    for _d in _days: days[_d] = _days[_d]\n",
    "                city_days_time[city] = days\n",
    "\n",
    "            city = parts[0]\n",
    "            days = {}\n",
    "\n",
    "        sunrise = return_time(parts[2])\n",
    "        sunset  = return_time(parts[3])\n",
    "        dl = dayLight(sunrise, sunset)\n",
    "        days[parts[1]] = dl\n",
    "\n",
    "if city in city_days_time:\n",
    "    _days = city_days_time[city]\n",
    "    for _d in _days: days[_d] = _days[_d]\n",
    "city_days_time[city] = days\n",
    "\n",
    "\n",
    "print('Successfully loaded daylight data for {} cities!'.format(len(city_days_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_roIRx9LPwcB"
   },
   "source": [
    "#### *3-8- créons un dictionnaires de daylight des indexes des villes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clkAvszZ7x7x"
   },
   "outputs": [],
   "source": [
    "# pre-load daylight mapping for different cities\n",
    "city_to_index_to_daylight = {}\n",
    "states = {'Houston':'TX', 'Charlotte':'NC', 'Dallas':'TX', 'Atlanta':'GA', 'Austin':'TX', 'LosAngeles':'CA'}\n",
    "for c in cities:\n",
    "    d_begin = begin.replace(tzinfo=pytz.timezone(time_zones[c]))\n",
    "    d_end   = end.replace(tzinfo=pytz.timezone(time_zones[c]))\n",
    "    index_to_daylight = {}\n",
    "    index = 0\n",
    "    while(d_begin < d_end):\n",
    "        dl = returnDayLight(c, states[c], d_begin)\n",
    "        index_to_daylight[index] = dl\n",
    "        index += 1\n",
    "        d_begin += timedelta(seconds=15*60)\n",
    "    city_to_index_to_daylight[c] = index_to_daylight\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QRlF7wmV4f1A"
   },
   "source": [
    "#### *3-9- Enfin créons des vecteurs features des villes choisies et récupérons les dataset créés*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EIwzHf4P4IxO"
   },
   "outputs": [],
   "source": [
    "# map each time-step to hour of day and day of the week; this should be consistent across different time-zones!\n",
    "timestep_to_dow_hod = {}\n",
    "d_begin = begin.replace(tzinfo=pytz.utc)\n",
    "d_end   = end.replace(tzinfo=pytz.utc)\n",
    "index = 0\n",
    "\n",
    "while(d_begin < d_end):\n",
    "    dow = d_begin.weekday()\n",
    "    hod = d_begin.hour    \n",
    "    timestep_to_dow_hod[index] = [dow, hod]\n",
    "    \n",
    "    d_begin += timedelta(seconds=15*60)    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 635916,
     "status": "ok",
     "timestamp": 1574098025288,
     "user": {
      "displayName": "Moustapha KINTY",
      "photoUrl": "",
      "userId": "03984028447163486280"
     },
     "user_tz": -60
    },
    "id": "dA1LECZg4eQ_",
    "outputId": "b37b225e-f938-4182-b857-b459e613f13c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LosAngeles in 113.5 sec! #vectors 1377636!\n",
      "Done with Houston in 179.3 sec! #vectors 2198919!\n",
      "Done with Austin in 94.2 sec! #vectors 1148030!\n",
      "Done with Dallas in 119.7 sec! #vectors 1448284!\n",
      "Done with Charlotte in 80.5 sec! #vectors 1006734!\n",
      "Done with Atlanta in 48.0 sec! #vectors 600508!\n"
     ]
    }
   ],
   "source": [
    "traffic_tags = ['Accident', 'BrokenVehicle', 'Congestion', 'Construction', 'Event', 'FlowIncident', 'Other', 'RoadBlocked']\n",
    "weather_tags = ['Condition', 'Event', 'Humidity', 'Precipitation', 'Pressure', 'Temperature', 'Visibility', 'WindSpeed']\n",
    "poi_tags = []\n",
    "start = time.time()\n",
    "condition_tags = set()\n",
    "\n",
    "for c in city_to_geohashes:\n",
    "    # creating vector for each reion (geohash) during a 15 minutes time interval. Such vector contains time, traffic, and weather attributes. \n",
    "    writer = open('data/vectors/{}_geo2vec_{}-{}.csv'.format(c, str(begin.year)+str(begin.month)+str(begin.day),\n",
    "                                                        str(end.year)+str(end.month)+str(end.day)), 'w')\n",
    "    writer.write('Geohash,TimeStep,DOW,HOD,DayLight,T-Accident,T-BrokenVehicle,T-Congestion,T-Construction,'\\\n",
    "        'T-Event,T-FlowIncident,T-Other,T-RoadBlocked,W-Humidity,W-Precipitation,W-Pressure,'\\\n",
    "        'W-Temperature,W-Visibility,W-WindSpeed,W-Rain,W-Snow,W-Fog,W-Hail\\n')\n",
    "    \n",
    "    traffic = city_to_geohashes[c]\n",
    "    weather = city_to_geohashes_to_weather[c]        \n",
    "    for g in traffic:\n",
    "        vectors = []\n",
    "        for i in range(len(traffic[g])):\n",
    "            v = []\n",
    "            for t in traffic_tags: v.append(traffic[g][i][t])\n",
    "            v_w = [0,0,0,0] # for rain, snow, fog, and hail\n",
    "            for w in weather_tags:\n",
    "                if w=='Condition' or w=='Event':      \n",
    "                    _tgs = weather[g][i][w]\n",
    "                    for _tg in _tgs: \n",
    "                        if 'rain' in _tg.lower() or 'drizzle' in _tg.lower() or 'thunderstorm' in _tg.lower(): v_w[0] = 1\n",
    "                        elif 'snow' in _tg.lower(): v_w[1] = 1\n",
    "                        elif 'fog' in _tg.lower() or 'haze' in _tg.lower() or 'mist' in _tg.lower() or 'smoke' in _tg.lower(): v_w[2] = 1\n",
    "                        elif 'hail' in _tg.lower() or 'ice pellets' in _tg.lower(): v_w[3] = 1                            \n",
    "                elif len(weather[g][i][w]) == 0: v.append(0)\n",
    "                else: v.append(np.mean(weather[g][i][w]))\n",
    "            for _v_w in v_w: v.append(_v_w)\n",
    "            vectors.append(v)\n",
    "        \n",
    "        for i in range(len(vectors)):\n",
    "            v = vectors[i]\n",
    "            v = [str(v[j]) for j in range(len(v))]\n",
    "            v = ','.join(v)\n",
    "            writer.write(g + ',' + str(i) + ',' + str(timestep_to_dow_hod[i][0]) + ',' + str(timestep_to_dow_hod[i][1]) \n",
    "                         + ',' + city_to_index_to_daylight[c][i] + ',' + v + '\\n')\n",
    "            \n",
    "    writer.close()\n",
    "    print('Done with {} in {:.1f} sec! #vectors {}!'.format(c, time.time()-start, len(traffic)*len(vectors)))\n",
    "    start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eaieRuVnSzpc"
   },
   "source": [
    "### !!! Fin de Generation des vecteurs features, pour la suite, voir le fichier !!!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "2. GenerateFeaturesVectors.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
